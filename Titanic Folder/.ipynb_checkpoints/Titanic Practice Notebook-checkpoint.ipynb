{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Prediction Problem Example\n",
    "______________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn.linear_model\n",
    "\n",
    "\n",
    "trainSet = pd.read_csv(r\"Titanic\\Data\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above code imports necessary libraries and reads in values from a .csv file and loads them into the _DataFrame type_ defined within the pandas library.**\n",
    "\n",
    "Entries are accessed via an indexing based on the columns of the csv file. For example, the TrainSet['Age'] access the column of the csv containing all of the ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop vals\n",
    "# trainSet.dropna(inplace=True)\n",
    "\n",
    "# Replace vals with mean\n",
    "trainSet.fillna(trainSet.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The entries without a value are replaced with a _NaN_ value which will cause problems in training if not handled correctly.** \n",
    "\n",
    "There are two main options here, using the **dropna** function, which removes rows that have _NaN_ values, or the **fillna** function which replaces these values with a preset value (i.e. the average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map version\n",
    "#trainSet['Sex'] = map(lambda x: 1 if x == 'male' else 0, trainSet['Sex'])\n",
    "\n",
    "# List comprehension version\n",
    "trainSet['Sex'] = [1 if i == 'male' else '0' for i in trainSet['Sex'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code prepares the data in the column which lists passengers in terms of gender. In order to train the logisitic regression model, this should be converted into numerical data**\n",
    "\n",
    "The two methods shown here are equally valid ways in completing that task; however, the second option, which uses a list comprehension, is much more readable that the first.\n",
    "\n",
    "_Note: A for loop can also be used, but it is slower than a list comprehension and does not provide a significant increase in readability in this particular instance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(trainSet[['Age','Sex','Pclass']]).reshape(-1,3)\n",
    "y = trainSet['Survived']\n",
    "model = sklearn.linear_model.LogisticRegression()\n",
    "model.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data needs to be reshaped so that it can be passed into the learning function.**\n",
    "\n",
    "The learning function in this model is **Logistic Regression**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet = pd.read_csv(r\"Titanic\\Data\\test.csv\")\n",
    "testSet.fillna(trainSet.mean(), inplace=True)\n",
    "testSet['Sex'] = map(lambda x: 1 if x == 'male' else 0, testSet['Sex'])\n",
    "X_test = np.array(testSet[['Age','Sex','Pclass']]).reshape(-1,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the code to prepare the testing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "for item in X_test:\n",
    "        res = model.predict(item.reshape(1,-1))\n",
    "        dataList.append(*res) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code iterates over each sample and and uses the previously trained model to make a list of predictions**\n",
    "\n",
    "The ***** in front of res strips the values of extra characters (i.e. [1] becomes 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "5            897         0\n",
      "6            898         1\n",
      "7            899         0\n",
      "8            900         1\n",
      "9            901         0\n",
      "10           902         0\n",
      "11           903         0\n",
      "12           904         1\n",
      "13           905         0\n",
      "14           906         1\n",
      "15           907         1\n",
      "16           908         0\n",
      "17           909         0\n",
      "18           910         1\n",
      "19           911         0\n",
      "20           912         0\n",
      "21           913         0\n",
      "22           914         1\n",
      "23           915         0\n",
      "24           916         1\n",
      "25           917         0\n",
      "26           918         1\n",
      "27           919         0\n",
      "28           920         0\n",
      "29           921         0\n",
      "..           ...       ...\n",
      "388         1280         0\n",
      "389         1281         0\n",
      "390         1282         0\n",
      "391         1283         1\n",
      "392         1284         0\n",
      "393         1285         0\n",
      "394         1286         0\n",
      "395         1287         1\n",
      "396         1288         0\n",
      "397         1289         1\n",
      "398         1290         0\n",
      "399         1291         0\n",
      "400         1292         1\n",
      "401         1293         0\n",
      "402         1294         1\n",
      "403         1295         1\n",
      "404         1296         0\n",
      "405         1297         0\n",
      "406         1298         0\n",
      "407         1299         0\n",
      "408         1300         1\n",
      "409         1301         1\n",
      "410         1302         1\n",
      "411         1303         1\n",
      "412         1304         1\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dataDict = {'PassengerId': testSet['PassengerId'], 'Survived': dataList}\n",
    "\n",
    "dataDF = pd.DataFrame.from_dict(dataDict)\n",
    "\n",
    "dataDF.to_csv(path_or_buf=r\"Titanic\\Data\\predictions.csv\",mode='w',index=False)\n",
    "\n",
    "print(dataDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This takes the data that was created and writes it to a csv file**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
